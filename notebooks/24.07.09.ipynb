{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lcw/workspace/panosupervised\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pythreejs as pjs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib.cm import get_cmap\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from IPython.core.display import display\n",
    "\n",
    "os.chdir('..')\n",
    "np.set_printoptions(precision=4)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidar.arch.models.depth.PanoSupervisedModel import PanoSupervisedModel\n",
    "from vidar.arch.networks.depth.MultiCamDepthNet import MultiCamDepthNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '/data/disk/logs/checkpoints/soft-tree-60/models/017.ckpt'\n",
    "# model = Depth()\n",
    "state_dict = torch.load(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['config', 'epoch', 'state_dict'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = state_dict['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = state_dict['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(arch=Config(losses=Config(smoothness=Config(file='SmoothnessLoss', gamma=0.5, normalize=True, weight=0.0001), supervised=Config(automask_loss=True, file='SupervisedDepthLoss', flow_downsampling=False, gamma=1.0, mask_sparse=True, method='huber', upsample_depth=False)), model=Config(file='depth/PanoSupervisedModel'), networks=Config(depth=Config(decoder=Config(activation='sigmoid', depth_focal=1.0, depth_hypothesis=[2, 3, 10, 30, 60, 90], downsample=False, file='decoders/PanoDepthDecoder', fusion_type='MultiDepthSweepFusion', input_cameras=['camera_01', 'camera_05', 'camera_06', 'camera_07', 'camera_08', 'camera_09'], num_ch_out=1, out_shape=[128, 1024], positional_encoding=16, ref_shape=[256, 2048], scale_and_shapes={'camera_01': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_05': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_06': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_07': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_08': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_09': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))]}, use_skips=True, view_attention=False), encoders=Config(camera_01=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_05=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_06=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_07=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_08=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_09=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18)), file='depth/MultiCamDepthNet', max_depth=200.0, min_depth=2.0, scale_invdepth='inverse'))), checkpoint=Config(folder='/data/disk/logs/chungwoo/checkpoints', keep_top=5, name='soft-tree-60', s3_bucket='chungwoolee', save_code=True), datasets=Config(train=Config(augmentation=Config(jittering=[0.2, 0.2, 0.2, 0.05], resize=[384, 640]), cameras=[[1, 5, 6, 7, 8, 9]], context=[-1, 1], dataloader=Config(batch_size=7, num_workers=5, pin_memory=True), depth_type=['lidar'], labels=['depth', 'pose'], masks=['/data/datasets/DDAD/mask'], name=['PanoCamOuroboros'], pano_cam_config=Config(height=256, name='panocam_56_0_150_z_-02_+02', phi_range=[0, 6.2831853072], position_in_world=[0.56, 0, 1.5], rho=1.0, width=2048, z_range=[-0.2, 0.2]), path=['/data/datasets/DDAD/ddad_train_val/ddad.json'], repeat=[1], split=['train']), validation=Config(augmentation=Config(resize=[384, 640]), cameras=[[1, 5, 6, 7, 8, 9]], context=[-1, 1], dataloader=Config(batch_size=7, num_workers=5, pin_memory=True), depth_type=['lidar'], labels=['depth', 'pose'], masks=['/data/datasets/DDAD/mask'], name=['PanoCamOuroboros'], pano_cam_config=Config(height=256, name='panocam_56_0_150_z_-02_+02', phi_range=[0, 6.2831853072], position_in_world=[0.56, 0, 1.5], rho=1.0, width=2048, z_range=[-0.2, 0.2]), path=['/data/datasets/DDAD/ddad_train_val/ddad.json'], split=['val'])), evaluation=Config(panodepth=Config(crop='', max_depth=200.0, median_scaling=True, min_depth=0.0, post_process=False, scale_output='resize')), optimizers=Config(depth=Config(lr=0.0001, name='Adam', scheduler=Config(gamma=0.5, step_size=20))), save=Config(depth=['viz', 'npz'], folder='/data/disk/logs/chungwoo/save', naming='filename', rgb=['tgt']), wandb=Config(entity='leecw0717', folder='/data/disk/logs', name='soft-tree-60', num_validation_logs=10, project='panodepth_res_net', tags=['batch_12', 'train_on_filtered_DDAD', 'depth_hypothesis', 'positional_encoding_16', 'resnet_encoders'], url='https://app.wandb.ai/leecw0717/panodepth_res_net/runs/qrcw2d41'), wrapper=Config(find_unused_parameters=True, flip_lr_prob=0.0, grad_accumulate_batches=0, grad_scaler=False, max_epochs=300, min_epochs=0, seed=42, sync_batch_norm=True, validate_first=False, validate_flipped=False))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "networks.depth.networks.encoders.camera_01.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_01.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_01.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_01.encoder.fc.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_05.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_05.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_05.encoder.fc.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_06.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_06.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_06.encoder.fc.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_07.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_07.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_07.encoder.fc.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_08.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_08.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_08.encoder.fc.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer1.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer2.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer3.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.0.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.0.downsample.1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.conv1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn1.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn1.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn1.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn1.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn1.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.conv2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn2.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn2.bias\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn2.running_mean\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn2.running_var\n",
      "networks.depth.networks.encoders.camera_09.encoder.layer4.1.bn2.num_batches_tracked\n",
      "networks.depth.networks.encoders.camera_09.encoder.fc.weight\n",
      "networks.depth.networks.encoders.camera_09.encoder.fc.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in state_dict['state_dict'].items():\n",
    "    if 'encoder' in k:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(arch=Config(losses=Config(smoothness=Config(file='SmoothnessLoss', gamma=0.5, normalize=True, weight=0.0001), supervised=Config(automask_loss=True, file='SupervisedDepthLoss', flow_downsampling=False, gamma=1.0, mask_sparse=True, method='huber', upsample_depth=False)), model=Config(file='depth/PanoSupervisedModel'), networks=Config(depth=Config(decoder=Config(activation='sigmoid', depth_focal=1.0, depth_hypothesis=[2, 3, 10, 30, 60, 90], downsample=False, file='decoders/PanoDepthDecoder', fusion_type='MultiDepthSweepFusion', input_cameras=['camera_01', 'camera_05', 'camera_06', 'camera_07', 'camera_08', 'camera_09'], num_ch_out=1, out_shape=[128, 1024], positional_encoding=16, ref_shape=[256, 2048], scale_and_shapes={'camera_01': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_05': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_06': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_07': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_08': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_09': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))]}, use_skips=True, view_attention=False), encoders=Config(camera_01=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_05=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_06=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_07=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_08=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_09=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18)), file='depth/MultiCamDepthNet', max_depth=200.0, min_depth=2.0, scale_invdepth='inverse'))), checkpoint=Config(folder='/data/disk/logs/chungwoo/checkpoints', keep_top=5, name='soft-tree-60', s3_bucket='chungwoolee', save_code=True), datasets=Config(train=Config(augmentation=Config(jittering=[0.2, 0.2, 0.2, 0.05], resize=[384, 640]), cameras=[[1, 5, 6, 7, 8, 9]], context=[-1, 1], dataloader=Config(batch_size=7, num_workers=5, pin_memory=True), depth_type=['lidar'], labels=['depth', 'pose'], masks=['/data/datasets/DDAD/mask'], name=['PanoCamOuroboros'], pano_cam_config=Config(height=256, name='panocam_56_0_150_z_-02_+02', phi_range=[0, 6.2831853072], position_in_world=[0.56, 0, 1.5], rho=1.0, width=2048, z_range=[-0.2, 0.2]), path=['/data/datasets/DDAD/ddad_train_val/ddad.json'], repeat=[1], split=['train']), validation=Config(augmentation=Config(resize=[384, 640]), cameras=[[1, 5, 6, 7, 8, 9]], context=[-1, 1], dataloader=Config(batch_size=7, num_workers=5, pin_memory=True), depth_type=['lidar'], labels=['depth', 'pose'], masks=['/data/datasets/DDAD/mask'], name=['PanoCamOuroboros'], pano_cam_config=Config(height=256, name='panocam_56_0_150_z_-02_+02', phi_range=[0, 6.2831853072], position_in_world=[0.56, 0, 1.5], rho=1.0, width=2048, z_range=[-0.2, 0.2]), path=['/data/datasets/DDAD/ddad_train_val/ddad.json'], split=['val'])), evaluation=Config(panodepth=Config(crop='', max_depth=200.0, median_scaling=True, min_depth=0.0, post_process=False, scale_output='resize')), optimizers=Config(depth=Config(lr=0.0001, name='Adam', scheduler=Config(gamma=0.5, step_size=20))), save=Config(depth=['viz', 'npz'], folder='/data/disk/logs/chungwoo/save', naming='filename', rgb=['tgt']), wandb=Config(entity='leecw0717', folder='/data/disk/logs', name='soft-tree-60', num_validation_logs=10, project='panodepth_res_net', tags=['batch_12', 'train_on_filtered_DDAD', 'depth_hypothesis', 'positional_encoding_16', 'resnet_encoders'], url='https://app.wandb.ai/leecw0717/panodepth_res_net/runs/qrcw2d41'), wrapper=Config(find_unused_parameters=True, flip_lr_prob=0.0, grad_accumulate_batches=0, grad_scaler=False, max_epochs=300, min_epochs=0, seed=42, sync_batch_norm=True, validate_first=False, validate_flipped=False))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PanoSupervisedModel(config.arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of PanoSupervisedModel(\n",
       "  (blocks): ModuleDict()\n",
       "  (networks): ModuleDict()\n",
       "  (losses): ModuleDict()\n",
       "  (flow_reverse): FlowReversal()\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PanoSupervisedModel(\n",
       "  (blocks): ModuleDict()\n",
       "  (networks): ModuleDict()\n",
       "  (losses): ModuleDict()\n",
       "  (flow_reverse): FlowReversal()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vidar.arch.models.depth.PanoSupervisedModel.PanoSupervisedModel"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_forward_unimplemented',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_input_keys',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'blocks',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'compute_losses',\n",
       " 'compute_pose',\n",
       " 'cpu',\n",
       " 'create_pano_mask',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'flow_reverse',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_num_scales',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'losses',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'networks',\n",
       " 'num_scales',\n",
       " 'parameters',\n",
       " 'produce_pano_image',\n",
       " 'produce_to_per_camera_depth',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'rgb_lidar',\n",
       " 'set_attr',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(depth=Config(decoder=Config(activation='sigmoid', depth_focal=1.0, depth_hypothesis=[2, 3, 10, 30, 60, 90], downsample=False, file='decoders/PanoDepthDecoder', fusion_type='MultiDepthSweepFusion', input_cameras=['camera_01', 'camera_05', 'camera_06', 'camera_07', 'camera_08', 'camera_09'], num_ch_out=1, out_shape=[128, 1024], positional_encoding=16, ref_shape=[256, 2048], scale_and_shapes={'camera_01': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_05': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_06': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_07': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_08': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))], 'camera_09': [(2, (64, 192, 320), 4, (64, 64, 512)), (4, (64, 96, 160), 8, (64, 32, 256)), (8, (128, 48, 80), 16, (128, 16, 128)), (16, (256, 24, 40), 32, (256, 8, 64)), (32, (512, 12, 20), 64, (512, 4, 32))]}, use_skips=True, view_attention=False), encoders=Config(camera_01=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_05=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_06=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_07=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_08=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18), camera_09=Config(file='encoders/ResNetEncoder', num_rgb_in=1, pretrained=True, ref_shape=[384, 640], version=18)), file='depth/MultiCamDepthNet', max_depth=200.0, min_depth=2.0, scale_invdepth='inverse'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.arch.networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of PanoSupervisedModel(\n",
       "  (blocks): ModuleDict()\n",
       "  (networks): ModuleDict()\n",
       "  (losses): ModuleDict()\n",
       "  (flow_reverse): FlowReversal()\n",
       ")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vidar.core.wrapper import Wrapper\n",
    "from vidar.utils.setup import setup_arch\n",
    "from vidar.utils.networks import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Path /data/datasets/DDAD/ddad_train_val/000000 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m \u001b[43mWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/core/wrapper.py:59\u001b[0m, in \u001b[0;36mWrapper.__init__\u001b[0;34m(self, cfg, ckpt, verbose)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Setup architecture, datasets and tasks\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39march \u001b[38;5;241m=\u001b[39m setup_arch(cfg\u001b[38;5;241m.\u001b[39march, checkpoint\u001b[38;5;241m=\u001b[39mckpt, verbose\u001b[38;5;241m=\u001b[39mverbose) \u001b[38;5;28;01mif\u001b[39;00m cfg_has(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets_cfg \u001b[38;5;241m=\u001b[39m \u001b[43msetup_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cfg_has(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m setup_metrics(cfg\u001b[38;5;241m.\u001b[39mevaluation) \u001b[38;5;28;01mif\u001b[39;00m cfg_has(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m     63\u001b[0m sync_batch_norm \u001b[38;5;241m=\u001b[39m cfg_has(cfg\u001b[38;5;241m.\u001b[39mwrapper, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msync_batch_norm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/utils/setup.py:202\u001b[0m, in \u001b[0;36msetup_datasets\u001b[0;34m(cfg, verbose, concat_modes, stack)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    201\u001b[0m     print0(pcolor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m###### \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfont))\n\u001b[0;32m--> 202\u001b[0m datasets[key] \u001b[38;5;241m=\u001b[39m \u001b[43msetup_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m datasets_cfg[key] \u001b[38;5;241m=\u001b[39m [datasets_cfg[key]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(datasets[key])\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m concat_modes:\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/utils/setup.py:133\u001b[0m, in \u001b[0;36msetup_dataset\u001b[0;34m(cfg, root, verbose)\u001b[0m\n\u001b[1;32m    130\u001b[0m context \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mcontext\n\u001b[1;32m    131\u001b[0m labels \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m--> 133\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg_has(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepeat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m repeat \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    136\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ConcatDataset([dataset \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat)])\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/datasets/PanoCamOuroborosDataset.py:78\u001b[0m, in \u001b[0;36mPanoCamOuroborosDataset.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     77\u001b[0m     pano_cfg \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpano_cam_config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpano_name \u001b[38;5;241m=\u001b[39m pano_cfg\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpano_cfg \u001b[38;5;241m=\u001b[39m pano_cfg\u001b[38;5;241m.\u001b[39mdict\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/datasets/PanoCamOuroborosDataset.py:60\u001b[0m, in \u001b[0;36mMultiCamOuroborosDataset.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_stack_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/panosupervised/vidar/datasets/OuroborosDataset.py:193\u001b[0m, in \u001b[0;36mOuroborosDataset.__init__\u001b[0;34m(self, split, tag, depth_type, input_depth_type, masks, do_stack_samples, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     extra_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_virtual_camera_datums\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m     }\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Initialize chosen dataset\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscene_dataset_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatum_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackward_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbwd_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfwd_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequested_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested_annotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_annotated_datums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_stack_samples \u001b[38;5;241m=\u001b[39m do_stack_samples\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/synchronized_dataset.py:473\u001b[0m, in \u001b[0;36mSynchronizedSceneDataset.__init__\u001b[0;34m(self, scene_dataset_json, split, datum_names, requested_annotations, requested_autolabels, backward_context, forward_context, accumulation_context, generate_depth_from_datum, only_annotated_datums, skip_missing_data, dataset_root, transform_accumulated_box_points, use_diskcache, autolabel_root, ignore_raw_datum)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Return SynchronizedDataset with scenes built from dataset.json\u001b[39;00m\n\u001b[1;32m    470\u001b[0m dataset_metadata \u001b[38;5;241m=\u001b[39m DatasetMetadata\u001b[38;5;241m.\u001b[39mfrom_scene_containers(\n\u001b[1;32m    471\u001b[0m     scenes, requested_annotations, requested_autolabels, autolabel_root\u001b[38;5;241m=\u001b[39mautolabel_root\n\u001b[1;32m    472\u001b[0m )\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatum_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatum_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequested_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested_annotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequested_autolabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested_autolabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackward_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackward_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_depth_from_datum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerate_depth_from_datum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_annotated_datums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_annotated_datums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_accumulated_box_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_accumulated_box_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautolabel_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautolabel_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_raw_datum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_raw_datum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/synchronized_dataset.py:94\u001b[0m, in \u001b[0;36m_SynchronizedDataset.__init__\u001b[0;34m(self, dataset_metadata, scenes, datum_names, requested_annotations, requested_autolabels, forward_context, backward_context, accumulation_context, generate_depth_from_datum, only_annotated_datums, transform_accumulated_box_points, autolabel_root, ignore_raw_datum)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monly_annotated_datums \u001b[38;5;241m=\u001b[39m only_annotated_datums \u001b[38;5;28;01mif\u001b[39;00m requested_annotations \u001b[38;5;129;01mor\u001b[39;00m requested_autolabels \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_accumulated_box_points \u001b[38;5;241m=\u001b[39m transform_accumulated_box_points\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatum_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatum_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequested_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested_annotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequested_autolabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested_autolabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautolabel_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautolabel_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_raw_datum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_raw_datum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/base_dataset.py:870\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, dataset_metadata, scenes, datum_names, requested_annotations, requested_autolabels, split, autolabel_root, ignore_raw_datum)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_datums(\n\u001b[1;32m    865\u001b[0m     datum_names, requested_annotations\u001b[38;5;241m=\u001b[39mrequested_annotations, requested_autolabels\u001b[38;5;241m=\u001b[39mrequested_autolabels\n\u001b[1;32m    866\u001b[0m )\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Calibration index\u001b[39;00m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# >>> (p_WS, Camera) = self.calibration_table[(calibration_key, datum_name)]\u001b[39;00m\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalibration_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_calibration_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;66;03m# Build index for each scene. See `SceneContainer.datum_index` for more details\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatum_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_datum_index()\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/base_dataset.py:1105\u001b[0m, in \u001b[0;36mBaseDataset._build_calibration_table\u001b[0;34m(scene_containers)\u001b[0m\n\u001b[1;32m   1103\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1104\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild calibration table for all scenes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1105\u001b[0m calibration_files \u001b[38;5;241m=\u001b[39m [scene_container\u001b[38;5;241m.\u001b[39mcalibration_files \u001b[38;5;28;01mfor\u001b[39;00m scene_container \u001b[38;5;129;01min\u001b[39;00m scene_containers]\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m proc:\n\u001b[1;32m   1107\u001b[0m     all_calibration_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(proc\u001b[38;5;241m.\u001b[39mmap(BaseDataset\u001b[38;5;241m.\u001b[39m_get_scene_calibration_table, calibration_files))\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/base_dataset.py:1105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1103\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1104\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild calibration table for all scenes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1105\u001b[0m calibration_files \u001b[38;5;241m=\u001b[39m [\u001b[43mscene_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibration_files\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m scene_container \u001b[38;5;129;01min\u001b[39;00m scene_containers]\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m proc:\n\u001b[1;32m   1107\u001b[0m     all_calibration_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(proc\u001b[38;5;241m.\u001b[39mmap(BaseDataset\u001b[38;5;241m.\u001b[39m_get_scene_calibration_table, calibration_files))\n",
      "File \u001b[0;32m~/workspace/dgp/dgp/datasets/base_dataset.py:327\u001b[0m, in \u001b[0;36mSceneContainer.calibration_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory)\n\u001b[1;32m    328\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading all scene calibrations in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory))\n\u001b[1;32m    329\u001b[0m calibration_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory, CALIBRATION_FOLDER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: Path /data/datasets/DDAD/ddad_train_val/000000 does not exist"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
