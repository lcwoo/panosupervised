{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lcw/workspace/panosupervised\n"
     ]
    }
   ],
   "source": [
    "%cd /home/lcw/workspace/panosupervised/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from vidar.datasets.augmentations.resize import resize_npy_preserve\n",
    "from vidar.geometry.camera_pano import PanoCamera\n",
    "from vidar.datasets.OuroborosDataset import load_from_file, save_to_file, generate_proj_maps\n",
    "from vidar.datasets.OuroborosDataset import OuroborosDataset\n",
    "from vidar.datasets.utils.misc import stack_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANO_CAMERA_NAME = 'camera_pano'\n",
    "\n",
    "\n",
    "def generate_pano_proj_maps(camera, Xw, Xl):\n",
    "    \"\"\"Render pointcloud on pano image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    camera: PanoCamera\n",
    "        Camera object with appropriately set extrinsics wrt world.\n",
    "    Xw: np.Array\n",
    "        3D point cloud (x, y, z) in the world coordinate. [N,3]\n",
    "    Xl: np.Array\n",
    "        3D point cloud (x, y, z) in the lidar coordinate. [N,3]\n",
    "    Returns\n",
    "    -------\n",
    "    depth: np.Array\n",
    "        Rendered pano depth image\n",
    "    \"\"\"\n",
    "    # Project the points\n",
    "    uv_tensor, rho_tensor = camera.project_points(Xw, normalize=False, return_z=True)\n",
    "    uv = uv_tensor[0].numpy().astype(int)\n",
    "    # Colorize the point cloud based on depth\n",
    "    rho = rho_tensor[0].numpy()\n",
    "\n",
    "    # Create an empty image to overlay\n",
    "    H, W = camera.hw\n",
    "    proj_depth = np.zeros((H, W), dtype=np.float32)\n",
    "    in_view = np.logical_and.reduce([(uv >= 0).all(axis=1), uv[:, 0] < W, uv[:, 1] < H, rho > 0])\n",
    "    uv, rho = uv[in_view], rho[in_view]\n",
    "\n",
    "    # TODO(sohwang): this is not enough, we need meshes and filter points by z-buffer.\n",
    "    # Sort by distance to pick closest one if multiple LiDAR points are projected onto a single pixel\n",
    "    order = np.argsort(rho)[::-1]\n",
    "    uv = uv[order]\n",
    "    rho = rho[order]\n",
    "    proj_depth[uv[:, 1], uv[:, 0]] = rho\n",
    "\n",
    "    # Calculate yaw angle in LiDAR coordinate\n",
    "    xx = Xl[in_view][:, 0]\n",
    "    yy = Xl[in_view][:, 1]\n",
    "    yaw = np.arctan2(yy, xx + 1e-6)\n",
    "\n",
    "    # HACK(soonminh): Reverse yaw to make it clockwise and add pi to start from backward\n",
    "    yaw = -yaw + np.pi\n",
    "\n",
    "    proj_angle = np.zeros((H, W), dtype=np.float32)\n",
    "    proj_angle[uv[:, 1], uv[:, 0]] = yaw\n",
    "\n",
    "    return proj_depth, proj_angle\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "#### DATASET\n",
    "########################################################################################################################\n",
    "class MultiCamOuroborosDataset(OuroborosDataset):\n",
    "    \"\"\"\n",
    "    MultiCamOuroborosDataset dataset class for MultiCam models, which inherits OuroborosDataset.\n",
    "    This class returns per-camera dictionary of batches for MultiCam models\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs, do_stack_samples=False)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        samples, lidar_sample = super().__getitem__(idx)\n",
    "\n",
    "        samples_dict = {sample['sensor_name'].lower(): stack_sample([sample]) for sample in samples}\n",
    "        samples_dict['idx'] = samples[0]['idx']\n",
    "        samples_dict.update(lidar_sample)\n",
    "        return samples_dict\n",
    "\n",
    "\n",
    "class PanoCamOuroborosDataset(MultiCamOuroborosDataset):\n",
    "    \"\"\"\n",
    "    PanoCamOuroborosDataset dataset class for PanoCam models, which inherits MultiCamOuroborosDataset.\n",
    "    This class returns per-camera dictionary of batches for PanoCam models and PanoDepth GT for evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pano_cfg = kwargs.pop('pano_cam_config')\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.pano_name = pano_cfg.name\n",
    "        self.pano_cfg = pano_cfg.dict\n",
    "\n",
    "    def panodepth_to_points(self, distance):\n",
    "        \"\"\"\n",
    "        Unproject depth from a camera's perspective into a world-frame pointcloud\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        depth : np.Array\n",
    "            Depth map to be lifted [H,W]\n",
    "        datum_idx : Int\n",
    "            Index of the camera\n",
    "        coord: String (world, ego, cam)\n",
    "            Coordinate of the output points\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pointcloud : np.Array\n",
    "            Lifted 3D pointcloud [Nx3]\n",
    "        \"\"\"\n",
    "        params = PanoCamera.params_from_config(self.pano_cfg)\n",
    "        hw = params['hw']\n",
    "        K = params['K']\n",
    "\n",
    "        Twc = params['Twc']\n",
    "        h, w = hw\n",
    "        pcl = PanoCamera(K[None], hw, Twc=Twc[None]).reconstruct_depth_map(\n",
    "            distance * torch.ones([1, 1, h, w]), to_world=True)\n",
    "        return pcl.numpy().reshape(3, -1).T\n",
    "\n",
    "\n",
    "    def create_pano_rays(self, distance=1.0):\n",
    "        image_shape = PanoCamera.params_from_config(self.pano_cfg)['hw']\n",
    "        pcl = self.panodepth_to_points(distance)\n",
    "\n",
    "        ### Calculate polar/azimuth angles in LiDAR coordinate\n",
    "        # [LiDAR coordinate convention] https://en.wikipedia.org/wiki/Spherical_coordinate_system\n",
    "        #   (X, Y, Z) = (N, W, U), where northing (N), westing(W), and upwardness (U)\n",
    "        #   polar angle (theta): measured from a fixed zenith direction\n",
    "        #   azimuth angle (phi): measured from negative X-axis (southing, S) on a reference (XY-) plane\n",
    "        r = np.linalg.norm(pcl, 2, axis=1)\n",
    "        x, y, z = pcl.T\n",
    "\n",
    "        # measured from Z-axis\n",
    "        theta = np.arccos(z / (r + 1e-6))\n",
    "        # measured from X-axis, counterclockwise\n",
    "        phi = np.arctan2(y, x + 1e-6)\n",
    "        # Make phi positive/clockwise angle\n",
    "        phi = -phi + np.pi\n",
    "\n",
    "        rays = np.stack([theta, phi], axis=0).reshape(2, *image_shape)\n",
    "        return rays\n",
    "\n",
    "\n",
    "        ### Calculate polar/azimuth angles in LiDAR coordinate\n",
    "        # [LiDAR coordinate convention] https://en.wikipedia.org/wiki/Spherical_coordinate_system\n",
    "        #   (X, Y, Z) = (N, W, U), where northing (N), westing(W), and upwardness (U)\n",
    "        #   polar angle (theta): measured from a fixed zenith direction\n",
    "        #   azimuth angle (phi): measured from negative X-axis (southing, S) on a reference (XY-) plane\n",
    "\n",
    "        image_shape = (self.pano_cfg['height'], self.pano_cfg['width'])\n",
    "\n",
    "        # TODO(soonminh): change to spherical coordinate\n",
    "        rho = self.pano_cfg['rho']\n",
    "        theta_range = [np.arctan2(abs(z), rho) for z in self.pano_cfg['z_range']]\n",
    "        theta_range[0] = np.pi / 2 - theta_range[0]\n",
    "        theta_range[1] += np.pi / 2\n",
    "\n",
    "        theta = np.linspace(*theta_range, num=image_shape[0])\n",
    "        phi = np.linspace(0, 2 * np.pi + 1e-6, num=image_shape[1])\n",
    "\n",
    "        theta, phi = np.meshgrid(theta, phi, indexing='ij')\n",
    "        rays = np.stack([theta, phi], axis=0)\n",
    "        return rays\n",
    "\n",
    "    def create_pano_proj_maps(self, filename, K, hw, Twc, depth_idx, depth_type):\n",
    "        \"\"\"\n",
    "        Creates the depth map for a camera by projecting LiDAR information.\n",
    "        It also caches the depth map following DGP folder structure, so it's not recalculated\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : String\n",
    "            Filename used for loading / saving\n",
    "        depth_idx : Int\n",
    "            Depth sensor index\n",
    "        depth_type : String\n",
    "            Which depth type will be loaded\n",
    "        world_points : np.Array [Nx3]\n",
    "            Points that will be projected (optional)\n",
    "        context : Int\n",
    "            Context value for choosing current of reference information\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        depth : np.Array\n",
    "            Depth map for that datum in that sample [H,W]\n",
    "        \"\"\"\n",
    "        filename_depth = '{}/{}.npz'.format(\n",
    "            os.path.dirname(self.path), filename.format('depth/{}'.format(depth_type)))\n",
    "        # Load and return if exists\n",
    "        try:\n",
    "            # Get cached depth map\n",
    "            # depth, depth_yaw = load_from_file(filename_depth, 'depth', 'depth_yaw')\n",
    "            depth, angle = load_from_file(filename_depth, ['depth', 'angle'])\n",
    "            return depth, angle\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Get lidar information\n",
    "        lidar_extrinsics = self.get_current('extrinsics', depth_idx)\n",
    "        lidar_points = self.get_current('point_cloud', depth_idx)\n",
    "        world_points = (lidar_extrinsics * lidar_points).T\n",
    "\n",
    "        # Create camera\n",
    "        camera = PanoCamera(K[None], hw, Twc=Twc[None])\n",
    "        world_points = torch.FloatTensor(world_points[None])\n",
    "\n",
    "        # Generate depth maps\n",
    "        depth, angle = generate_pano_proj_maps(camera, world_points, lidar_points)\n",
    "\n",
    "        save_to_file(filename_depth, {'depth': depth, 'angle': angle})\n",
    "        return depth, angle\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        samples = super().__getitem__(idx)\n",
    "        filename_chunk = self.get_filename(idx, 0).split('/')\n",
    "        filename_chunk[-2] = os.path.join(PANO_CAMERA_NAME.upper(), self.pano_name)\n",
    "        filename = '/'.join(filename_chunk)\n",
    "\n",
    "        # lidar_pose = torch.FloatTensor(self.get_current('pose', self.depth_idx).matrix).inverse()\n",
    "\n",
    "        # Extrinsics: A pose of sensor wrt the body frame. (but maybe corrupted? not sure yet.)\n",
    "        # Pose: 4 x 4 transformation from sensor to world\n",
    "\n",
    "        # From dgp/datasets/base_dataset.py:L1381\n",
    "        # \"extrinsics\": Pose\n",
    "        #   Camera extrinsics with respect to the vehicle frame, if available.\n",
    "        # \"pose\": Pose\n",
    "        #   Pose of sensor with respect to the world/global/local frame\n",
    "        #   (reference frame that is initialized at start-time). (i.e. this\n",
    "        #   provides the ego-pose in `pose_WC`).\n",
    "\n",
    "        # TODO(soonminh): follow the same convention with OuroborosDataset\n",
    "        # e.g. some entities such as intrinsics and depth should be dicts by context index\n",
    "        params = PanoCamera.params_from_config(self.pano_cfg)\n",
    "        hw = params['hw']\n",
    "        K = params['K']\n",
    "        # Twc = params['Twc'] @ lidar_pose\n",
    "        # extrinsics = params['Twc']\n",
    "        # Twc = extrinsics @ lidar_pose\n",
    "        # Twc = extrinsics\n",
    "        Twc = params['Twc']\n",
    "        samples[PANO_CAMERA_NAME.lower()] = {\n",
    "            'filename': {0: filename},\n",
    "            'hw': hw,\n",
    "            'intrinsics': {0: K},\n",
    "            'Twc': Twc,\n",
    "            # 'extrinsics': {0: extrinsics}\n",
    "        }\n",
    "\n",
    "        # Rays\n",
    "        if self.with_rays:\n",
    "            rays = self.create_pano_rays()\n",
    "            embedding = np.stack([\n",
    "                np.sin(rays[0]),\n",
    "                np.cos(rays[0]),\n",
    "                np.sin(rays[1]),\n",
    "                np.cos(rays[1]),\n",
    "            ], axis=0)\n",
    "            samples[PANO_CAMERA_NAME.lower()].update({\n",
    "                'rays': {0: rays},\n",
    "                'rays_embedding': {0: embedding},\n",
    "            })\n",
    "\n",
    "        for i in range(self.num_cameras):\n",
    "            camera = self.get_current('datum_name', i).lower()\n",
    "            pose_to_pano = Twc @ torch.FloatTensor(samples[camera]['extrinsics'][0]).inverse()\n",
    "            # pose_to_pano = Twc @ torch.FloatTensor(samples[camera]['pose'][0]).inverse() # (camera -> world) -> (world -> pano) == (camera -> pano)\n",
    "            # pose_to_pano_orig = params['Twc'] @ torch.FloatTensor(samples[camera]['extrinsics'][0]).inverse()\n",
    "            samples[camera]['pose_to_pano'] = {0: pose_to_pano}\n",
    "\n",
    "        if self.with_depth:\n",
    "            depth, angle = self.create_pano_proj_maps(filename, K, hw, Twc, self.depth_idx, self.depth_type)\n",
    "            depth = resize_npy_preserve(depth, hw, expand_dims=False)\n",
    "            angle = resize_npy_preserve(angle, hw, expand_dims=False)\n",
    "            samples[PANO_CAMERA_NAME.lower()]['depth'] = {0: depth.astype(np.float32)[None]}\n",
    "            samples[PANO_CAMERA_NAME.lower()]['angle'] = {0: angle.astype(np.float32)[None]}\n",
    "\n",
    "        return samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of frames: 98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from struct import pack, unpack\n",
    "\n",
    "from vidar.datasets.utils.transforms import get_transforms\n",
    "from vidar.utils.config import Config\n",
    "from vidar.utils.viz import viz_depth\n",
    "\n",
    "height, width = (384, 640)\n",
    "height_pano, width_pano = (256, 2048)\n",
    "params = {\n",
    "    'name': 'PanoCamOuroboros',\n",
    "    'path': '/data/datasets/DDAD/ddad_train_val/ddad_overfit_000071.json',\n",
    "    # 'path': '/data/datasets/DDAD/ddad_train_val/ddad.json',\n",
    "    'split': 'train',\n",
    "    'context': [-1, 1],\n",
    "    'labels': ['depth', 'pose'],\n",
    "    'cameras': [1, 5, 6, 7, 8, 9],\n",
    "    'depth_type': 'lidar',\n",
    "    'repeat': 1,\n",
    "    'pano_cam_config': Config(**{\n",
    "        'name': 'panocam_150_z_-02_+02',\n",
    "        'height': height_pano,\n",
    "        'width': width_pano,\n",
    "        'position_in_world': [0, 0, 1.5],\n",
    "        'phi_range': [0, 6.2831853072],\n",
    "        'rho': 1.0,\n",
    "        'z_range': [-0.2, 0.2]}),\n",
    "    'data_transform':\n",
    "        get_transforms('train', Config(**{'resize': [height, width]})),\n",
    "}\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = PanoCamOuroborosDataset(**params)\n",
    "print('# of frames: {}'.format(len(dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB from 000071/{}/CAMERA_01/1568648968795297\n",
      "RGB from 000071/{}/CAMERA_05/1568648968795297\n",
      "RGB from 000071/{}/CAMERA_06/1568648968795297\n",
      "RGB from 000071/{}/CAMERA_07/1568648968795297\n",
      "RGB from 000071/{}/CAMERA_08/1568648968795297\n",
      "RGB from 000071/{}/CAMERA_09/1568648968795297\n",
      "Save to 000071_1568648968795297_frame.png\n",
      "Save to 000071_1568648968795297_point_cloud.pcd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get a sample\n",
    "data = dataset[50]\n",
    "\n",
    "scene, *_, timestamp = data['camera_01']['filename'][0].split('/')\n",
    "filename = f'{scene}_{timestamp}'\n",
    "panodepth = data['camera_pano']['depth']\n",
    "panodepth_viz = (viz_depth(panodepth[0][0], filter_zeros=False) * 255.0).astype(np.uint8)\n",
    "tensor_to_rgb_viz = lambda x: (x.permute(1, 2, 0) * 255.0).numpy().astype(np.uint8)\n",
    "rgbs = np.hstack(\n",
    "    [tensor_to_rgb_viz(data[c]['rgb'][0]) for c in data.keys() if c.startswith('camera_0')]\n",
    ")\n",
    "\n",
    "rgbs = cv2.resize(rgbs, (panodepth_viz.shape[1], panodepth_viz.shape[0]))\n",
    "\n",
    "# From PanoDepth to ImageDepth\n",
    "panodepth_tensor = torch.FloatTensor(panodepth[0])[None]\n",
    "params = PanoCamera.params_from_config(params['pano_cam_config'].dict)\n",
    "camera = PanoCamera(params['K'][None], params['hw'], params['Twc'][None])\n",
    "\n",
    "# xyz_lidar = camera.reconstruct_depth_map(panodepth_tensor, to_world=True)\n",
    "xyz_lidar = camera.reconstruct_depth_map(panodepth_tensor, to_world=False)\n",
    "xyz_lidar = xyz_lidar.view(3, -1).numpy()\n",
    "rgb_lidar = np.zeros_like(xyz_lidar).T\n",
    "for camera in dataset.sensors:\n",
    "    if not camera.startswith('camera'):\n",
    "        continue\n",
    "    print('RGB from {}'.format(data[camera]['filename'][0]))\n",
    "\n",
    "    K = data[camera]['intrinsics'][0].numpy()\n",
    "    # Twc = data[camera]['extrinsics'][0].numpy()\n",
    "    # xyz_camera = Twc[:3, :3] @ xyz_lidar + Twc[:3, 3:]\n",
    "    Tpc = np.linalg.inv(data[camera]['pose_to_pano'][0])\n",
    "    xyz_camera = Tpc[:3, :3] @ xyz_lidar + Tpc[:3, 3:]\n",
    "    ix, iy, iz = K @ xyz_camera\n",
    "    ix, iy = ((ix / iz).astype(np.int16), (iy / iz).astype(np.int16))\n",
    "\n",
    "    proj_on_image = np.logical_and.reduce([\n",
    "        xyz_camera[2] > 0,\n",
    "        ix >= 0, ix < width,\n",
    "        iy >= 0, iy < height,\n",
    "    ])\n",
    "\n",
    "    image = data[camera]['rgb'][0].permute(1, 2, 0).numpy()\n",
    "    rgb_lidar[proj_on_image] = image[iy[proj_on_image], ix[proj_on_image], :]\n",
    "\n",
    "xyz_lidar = xyz_lidar.T\n",
    "rgb_lidar = (rgb_lidar * 255.0).astype(np.uint8)\n",
    "\n",
    "rgb_lidar_image = rgb_lidar.reshape(height_pano, width_pano, 3)\n",
    "\n",
    "Image.fromarray(np.vstack([rgbs, panodepth_viz, rgb_lidar_image])).save(filename + '_frame.png')\n",
    "print('Save to {}'.format(filename + '_frame.png'))\n",
    "\n",
    "# Save to pcd/ply\n",
    "save_to_ply = False\n",
    "if save_to_ply:\n",
    "    # preview on mac\n",
    "    HEADER = (\n",
    "        'ply',\n",
    "        'format ascii 1.0',\n",
    "        'element vertex {}'.format(len(xyz_lidar)),\n",
    "        'property float x',\n",
    "        'property float y',\n",
    "        'property float z',\n",
    "        'property uchar red',\n",
    "        'property uchar green',\n",
    "        'property uchar blue',\n",
    "        'end_header',\n",
    "    )\n",
    "    suffix = '_point_cloud.ply'\n",
    "    def write_func(f, x, y, z, r, g, b):\n",
    "        f.write(('{:.4f} ' * 6 + '\\n').format(x, y, z, r, g, b))\n",
    "else:\n",
    "    # open3d\n",
    "    HEADER = (\n",
    "        '# .PCD v0.7 - Point Cloud Data file format',\n",
    "        'VERSION 0.7',\n",
    "        'FIELDS x y z rgb',\n",
    "        'SIZE 4 4 4 4',\n",
    "        'TYPE F F F F',\n",
    "        'COUNT 1 1 1 1',\n",
    "        'WIDTH {}'.format(len(xyz_lidar)),\n",
    "        'HEIGHT 1',\n",
    "        'VIEWPOINT 0 0 0 1 0 0 0',\n",
    "        'POINTS {}'.format(len(xyz_lidar)),\n",
    "        'DATA ascii',\n",
    "    )\n",
    "    suffix = '_point_cloud.pcd'\n",
    "    def write_func(f, x, y, z, r, g, b):\n",
    "        rgb = b | g << 8 | r << 16\n",
    "        rgb = unpack('f', pack('i', rgb))[0]\n",
    "        f.write(('{} ' * 3 + '{}\\n').format(x, y, z, rgb))\n",
    "\n",
    "rgb_lidar = rgb_lidar.astype(np.uint32)\n",
    "print('Save to {}'.format(filename + suffix))\n",
    "with open(filename + suffix, 'w') as f:\n",
    "    f.write('\\n'.join(HEADER) + '\\n')\n",
    "    for (x, y, z), (r, g, b) in zip(xyz_lidar, rgb_lidar):\n",
    "        write_func(f, x, y, z, r, g, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
